import scrapy
import urlparse
from tutorial.items import TutorialItem
from scrapy.selector import Selector
from scrapy.http import Request



class MySpider(scrapy.Spider):
    name = 'amazy'
    allowed_domains = ['amazon.in']
    start_urls = ['http://www.amazon.in/s/ref=sr_nr_n_1?fst=as%3Aoff&rh=n%3A1805560031%2Ck%3Amobiles&keywords=mobiles&ie=UTF8&qid=1437540979&rnid=3576079031']
    global flag;
    flag =0;    
    def parse(self, response):
  
        res_arr = response.xpath('//div[contains(@class,"s-item-container")]')
        for res in res_arr:
    
            item = TutorialItem()
            link_arr = res.xpath('.//div[contains(@class,"a-section a-spacing-none a-inline-block s-position-relative")]/a/@href')
            link = link_arr[0].extract()
            item['link_from_am'] = link
            
            item['title'] = res.xpath(
                './/div[contains(@class,"a-row a-spacing-none")]/a/@title').extract()            
       	    if not item['title']:
            	item['title']="n/a"
        	
            item['price_from_am'] = res.xpath(
                './/div[contains(@class,"a-row a-spacing-none")]/a/span[contains(@class,"a-size-base a-color-price s-price a-text-bold")]/text()').extract()
            if not item['price_from_am']:
            	item['price_from_am']="n/a"
            
            request = scrapy.Request(link, callback=self.tech_details)
            print request 
            
            
            request.meta['item'] = item
		    			            
           
            yield request
            	          
        href = response.xpath('//a[@id="pagnNextLink"]/@href').extract()[0] #urlparse is for making absolute path(i.e. url) form relative path(i.e. href)
        url = urlparse.urljoin(response.url, href)
        yield scrapy.Request(url, callback=self.parse)



    def tech_details(self, response):
        flag=0
        item = response.meta["item"]
        
        hxs = Selector(response)
       
       	item['image_src'] = hxs.select(
            ".//div[contains(@class,'imgTagWrapper')]/img/@src").extract()
        if not item['image_src']:
            item['image_src']="n/a"
        else:
            item['image_src']=item['image_src'][0]

        item['color'] = hxs.xpath("//div[contains(@id,'prodDetails')]/div[contains(@class,'disclaim')]/strong/text()").extract()
        
     #   if not item['color']:
     #       item['color']="n/a"
    #    else:
    #        item['color'] = str(item['color']).encode('utf-8').lower()	     
	
	                  
        #Select Details Table      
        rows = hxs.xpath("//div[contains(@class,'pdTab')]/table/tbody/tr")
   
        item['internal'] = rows.xpath("td[.='Memory Storage Capacity']/following-sibling::td[1]/text()").extract()
        if not item['internal']:
           item['internal']="n/a"	 			
           
        if item['internal']=="n/a" :	 			   
           flag = 1
        item['internal']=str(item['internal'][0]).encode('utf-8').strip()   
        internal=str(item['internal']).split( )
        if len(internal) == 2:
           if internal[1] !="GB":
                    item['internal']=float(internal[0]/1024)
           else:
                    item['internal']=float(internal[0])
   
	item['color']= rows.xpath("td[.='Colour']/following-si	bling::td[1]/text()").extract()            
           
           
            
        #item['brand'] = rows.xpath("td[.='Brand']/following-sibling::td[1]/text()").extract()
            
	#item['ScreenSize'] = rows.xpath("td[.='Screen Size']/following-sibling::td[1]/text()").extract()	
	     
	#item['weight'] = rows.xpath("td[.='Item Weight']/following-sibling::td[1]/text()").extract()
	
	if flag==1 :
            return flag
        
        return item     
            
            
